{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Session 5\n",
    "\n",
    "The problems in this notebook will cover the content covered in our Inference I lectures including:\n",
    "- Hypothesis Testing\n",
    "- Confidence Intervals\n",
    "- Linear Regression Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The dangers of early peeking in A/B testing\n",
    "\n",
    "One especially common use of hypothesis testing in data science is \"A/B testing\".\n",
    "\n",
    "Many companies prioritize data informed decision making and have very mature A/B testing platforms to trial changes before adoption.  Here is an example of an A/B test which comes from the book \"Trustworthy Online Controlled Experiments\" by Kohavi, Tang and Xu:\n",
    "\n",
    "Someone at your company proposes implementing a coupon code system.  To rapidly get some idea of the potential impacts even *before* implementing the complete system you decide to implement the following A/B test:  for a period of two weeks you will show half of your customers your standard checkout page (the \"control group\"), and you will show the other half a new checkout page which has a coupon code box (the \"treatment group\"). Since there are no coupon codes in existence yet, putting anything in the box will simply display \"invalid code\" and otherwise do nothing.\n",
    "\n",
    "You will monitor how customers interact with the coupon code box (how many people click on it, enter anything into it, enter one or more attempted codes, etc), how long they stay on the checkout page in the control and treatment group, what fraction of customers who make it to the checkout page who actually complete their purchase, and the revenue per customer who made it to the checkout page.\n",
    "\n",
    "In this example, the mere presence of a coupon code box significantly reduced revenue per customer with an effect size large enough to scuttle the project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common (but ill advised) for companies to **continuously** monitor such experiments and stop early when a significant result is obtained in either direction.  The reasoning is that we would not want to continue a disastrous experiment for the full planned time (e.g.  hardly anyone checks out after being presented with the coupon code box), and we would likewise not want to miss out on the benefits by **not** implementing a positive experiment as soon as possible.\n",
    "\n",
    "In this exercise we will see why early stopping is such a bad idea through simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)\n",
    "\n",
    "Finish the definition of the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def simulate_data(control_mean, treatment_mean, scale, size):\n",
    "    '''\n",
    "    Draws from two normal distributions with the same scale and different means\n",
    "\n",
    "    Args:\n",
    "        control_mean:  the mean of the control group\n",
    "        treatment_mean: the mean of the treatment group\n",
    "        scale: the common standard deviation of both groups\n",
    "        size: the shape of both outputs\n",
    "    \n",
    "    returns:\n",
    "        The tuple (control_data, treatment_data)        \n",
    "    '''\n",
    "    control_data = \n",
    "    treatment_data = \n",
    "    return (control_data, treatment_data)\n",
    "\n",
    "\n",
    "# Note: for the probabilistic checks below, the probability of both false positive and negatives are so low as to be effectively zero\n",
    "# It is a fun little puzzle to estimate these probabilities.\n",
    "assert(simulate_data(3,3,1,(10,2))[0].shape == (10,2)), \"control_data does not have the correct shape\"\n",
    "assert(simulate_data(3,3,1,(10,2))[1].shape == (10,2)), \"treatment_data does not have the correct shape\"\n",
    "assert(np.abs(simulate_data(0,3,1,(1000))[0].mean()) < 1  ), \"control_data does not have the correct mean\"\n",
    "assert(np.abs(simulate_data(0,3,1,(1000))[1].mean() - 3) < 1  ), \"treatment_data does not have the correct mean\"\n",
    "assert(np.abs(simulate_data(0,3,1,(1000))[0].std() - 1) < 0.5 ), \"control_data does not have the correct standard deviation\"\n",
    "assert(np.abs(simulate_data(0,3,1,(1000))[1].std() - 1) < 0.5 ), \"treatment_data does not have the correct standard deviation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)\n",
    "\n",
    "Use  [`ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) to finish writing the following two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "\n",
    "def no_early_peeking_results(control_data, treatment_data):\n",
    "    '''\n",
    "    Returns the p-value of the t-test comparing the two group means.\n",
    "    '''\n",
    "    p_value = \n",
    "    return p_value\n",
    "\n",
    "assert(no_early_peeking_results([1,2,3], [4,5,6]) == 0.021311641128756727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_peeking_results(control_data, treatment_data, alpha):\n",
    "    '''\n",
    "    Runs a t-test on each initial segment of the control and treatment data.\n",
    "\n",
    "    Args:\n",
    "        alpha: the threshold for significance.\n",
    "        \n",
    "    Returns: \n",
    "        (p_value, nobs)\n",
    "        p_value: the p-value of the first significant such test\n",
    "        nobs: the number of observations in that test\n",
    "    \n",
    "    Example:  \n",
    "        early_peeking_results([1,2,2,2,2,2], [4,5,5,5,5,5], 0.05)\n",
    "        Should run a t-test on \n",
    "            [1,2], [4,5]\n",
    "            [1,2,2], [4,5,5]\n",
    "            [1,2,2,2], [4,5,5,5]\n",
    "            etc\n",
    "        when a significant p-value is found it will output\n",
    "        that p-value and the length of the control group for that test.\n",
    "    '''\n",
    "    \n",
    "    return p_value, nobs\n",
    "\n",
    "assert(early_peeking_results([1,2,2,2,2,2], [4,5,5,5,5,5], 0.05)[0] == 0.0031255892524457277)\n",
    "\n",
    "# Be careful about off by one errors here!\n",
    "assert(early_peeking_results([1,2,2,2,2,2], [4,5,5,5,5,5], 0.05)[1] == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c)\n",
    "\n",
    "We will now see the impact of early peeking on the false positive rate.\n",
    "\n",
    "By setting both the control and training mean to 0, and $\\alpha = 0.05$ for the threshold for significance, we should expect to see a false positive rate of roughly $0.05$.  We will see that early peeking wildly inflates the false positive rate!\n",
    "\n",
    "This is bad news for our company, because we will be mislead into thinking that our treatment has a significant effect (in either direction) when there really is no effect at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparing_procedures(size = 1000, \n",
    "                         num_simulations = 100, \n",
    "                        alpha = 0.05):\n",
    "    '''\n",
    "    Simulates data from control and treatment groups both with mean 0 and variance 1.\n",
    "    Returns a tuple of the following variables:\n",
    "        no_early_peeking_false_positives of type int\n",
    "            Number of significant trials without early peeking\n",
    "        early_peeking_false_positives of type int\n",
    "            Number of \"significant\" trials with early peeking\n",
    "        early_peeking_nobs of type list(int)\n",
    "            List of the number of samples in the \"significant\" early peeking trials.\n",
    "    '''            \n",
    "    no_early_peeking_false_positives = 0\n",
    "    early_peeking_false_positives = 0\n",
    "    early_peeking_nobs = []\n",
    "\n",
    "    for i in range(num_simulations):\n",
    "        # Your code here\n",
    "        \n",
    "    return (no_early_peeking_false_positives, early_peeking_false_positives, early_peeking_nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 100\n",
    "size = 1000\n",
    "(no_early_peeking_false_positives, early_peeking_false_positives, early_peeking_nobs) = comparing_procedures(num_simulations=num_simulations, size = size)\n",
    "print(f\"The number of false positives with no early peeking is {no_early_peeking_false_positives} out of {num_simulations}\")\n",
    "print(f\"The number of false positives with early peeking is {early_peeking_false_positives} out of {num_simulations}\")\n",
    "print(f\"The number of observations to reach those false positives (out of {size}) were \\n {early_peeking_nobs[early_peeking_nobs != 1000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Confidence Intervals and Linear Regression Coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Problem introduction\n",
    "\n",
    "The following [dataset](https://dasl.datadescription.com/datafile/bodyfat/) comes from the [Data and Story Library](https://dasl.datadescription.com/). \n",
    "\n",
    "Our target variable is `Pct.BF` which stands for \"percent body fat\".\n",
    "\n",
    "Age is given in years, weight is given in pounds, and all other measurements are given in inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = pd.read_csv('../../data/bodyfat.csv')\n",
    "bf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table does not include [Body Mass Index](https://en.wikipedia.org/wiki/Body_mass_index), but we can calculate it from the data.\n",
    "\n",
    "Add a new column `BMI` which records this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf['BMI'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the target variable `Pct.BF` is a bit problematic for `statsmodels` because of the period.  Change the name of that column to `BFP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)  Train/Test Split\n",
    "\n",
    "One of the reasons that we have a reproducibility crisis in several fields of science is that researchers test multiple hypotheses on their full dataset and only report the statistically significant findings.  As you should know, assuming that the null hypotheses are actually all true you will find one \"significant\" result for every $20$ things you try.\n",
    "\n",
    "Even without deliberate \"p-hacking\" one can still be led astray as the article [\"The Garden of Forking Paths\"](http://www.stat.columbia.edu/%7Egelman/research/unpublished/p_hacking.pdf) by Gelman and Loken so convincingly argues.  \n",
    "\n",
    "One way to combat this is by conducting a replication study, but that can be expensive.\n",
    "\n",
    "Alternatively can conduct your own replication study by splitting your data in half.  Experiment to your hearts content on the training data.  Find whatever interesting potential associations you like without worrying.  Then test one of these hypotheses on your testing set.  The downside is that your study is less powerful since you have access to only half the data.  The upside is that the data used to generate your research hypothesis is not the same data which you use to test your hypothesis (a very good thing).\n",
    "\n",
    "For these reasons, make a 50/50 train test split of the bodyfat data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import \n",
    "\n",
    "bf_train, bf_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Exploring possible associations\n",
    "\n",
    "Fit the following regression models using `statsmodels` (not `sklearn`):\n",
    "\n",
    "Note:  We imported `statsmodels.formula.api` as `smf`.  It is convenient to use formulas for fitting these models.  For example, if you wanted to regress `Neck` on `Chest` and `Height` you could write\n",
    "\n",
    "```python\n",
    "neck_model = smf.ols('Neck ~ Chest + Height', data=bf_train).fit()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model uses BMI, Waist, and Abdomen as features\n",
    "full_model = \n",
    "\n",
    "# waist_model uses Waist as the only feature\n",
    "waist_model = \n",
    "\n",
    "# bmi_model uses BMI as the only feature\n",
    "bmi_model = \n",
    "\n",
    "# abdomen_model uses abdomen as the only feature\n",
    "abdomen_model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the summary of each model.  Do they tell a consistent story?\n",
    "\n",
    "For each model discuss the following with your group:\n",
    "\n",
    "1. Describe *precisely* what is the meaning of the $p$-value listed for each feature.\n",
    "2. Describe *precisely* what is the meaning of the $95\\%$ confidence interval listed for each feature.\n",
    "2. How can it be that a feature is considered significant by one model and not by another?\n",
    "3. Can you explain any unusual findings? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abdomen_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an F-test to compare the full model to the waist, abdomen, and bmi models.  What is the precise meaning of the $p$-value of each test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the F-test\n",
    "f_test_waist = \n",
    "f_test_bmi = \n",
    "f_test_abdomen = \n",
    "\n",
    "\n",
    "print(\"p-value of full compared to waist model:\", f_test_waist[1])\n",
    "print(\"p-value of full compared to abdomen model:\", f_test_abdomen[1])\n",
    "print(\"p-value of full compared to BMI model:\", f_test_bmi[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not already, make a plot of `waist` against `abdomen` to help explain what we have been seeing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)  Final model evaluation on testing set.\n",
    "\n",
    "Let's choose the waist model as our final model.  Fit the model to the testing data and look at the summary.  Discuss with your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = \n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Confidence and prediction intervals\n",
    "\n",
    "Make a graph which includes:\n",
    "\n",
    "1. A scatterplot of the data\n",
    "2. The confidence interval for the predicted mean response.\n",
    "3. The prediction interval for the response.\n",
    "\n",
    "Note:  You will want to use the [`.get_predictions`](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.get_prediction.html) method of an ols model which returns prediction results. These prediction results then have a [`.summary_frame`](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.PredictionResults.summary_frame.html) method (the documentation is non-existent and you will need to look at the source to see what this does) which contain the confidence and prediction interval bounds you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the confidence and prediction interval for Body Fat Percentage at a waist size of 45 inches.  Explain these in a way that a layman could understand what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
